{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "159c21f0",
   "metadata": {},
   "source": [
    "### Import Libraries and Define Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00f64ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "import socket\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from urllib.parse import urlparse,parse_qs\n",
    "from collections import defaultdict\n",
    "from helpers import RateLimiter\n",
    "from bs4 import BeautifulSoup\n",
    "    \n",
    "ORIGINAL_SEED_URLS = './data/Urls.txt'\n",
    "TARGET_DOMAIN = 'avature.net'\n",
    "REDIRECT_TAG = 'mailRedir'\n",
    "TRACK_TAG = 'ltrk'\n",
    "CAREER_KEYWORDS = ['career', 'job', 'talent', 'recruit', 'apply']\n",
    "TARGET_REGISTRY_PATH = './data/avature_tenants.csv'\n",
    "EXPANDED_SEED_URLS= './data/expanded_urls.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9aa94d8",
   "metadata": {},
   "source": [
    "### Load the Seed URLS and verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30a60f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Seed Urls: 781635\n",
      "first five seed Urls\n",
      ": ['https://fmlogistic.avature.net/ro_RO/careers/_indeedLogin?jobId=5225', 'https://nva.avature.net/jobs/SearchJobs/?3_83_3=430600000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000&jobOffset=1370', 'https://nva.avature.net/jobs/SearchJobs/?3_83_3=2783030000000000&jobOffset=1730', 'https://nva.avature.net/jobs/SearchJobs/?3_83_3=430600000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000&jobOffset=300', 'https://premium.avature.net/en_US/jobs/PipelineDetail/Wireless-Sales-Pro/32786']\n"
     ]
    }
   ],
   "source": [
    "# Load de-duplicated seed-urls\n",
    "seed_url_list=set()\n",
    "try:\n",
    "    with open(ORIGINAL_SEED_URLS,'r') as seed_file:\n",
    "        for line in seed_file:\n",
    "            seed_url_list.add(line.strip())\n",
    "except FileNotFoundError:\n",
    "    print(\"unable to retrieve file path\")\n",
    "\n",
    "# Verify count and sample\n",
    "seed_url_list=list(seed_url_list)\n",
    "print(f\"Total Seed Urls: {len(seed_url_list)}\")\n",
    "print(f\"first five seed Urls\\n: {seed_url_list[:5]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c00f81",
   "metadata": {},
   "source": [
    "### Define base Tenants and corresponding Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "121efab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tenants=defaultdict(set)\n",
    "for url in seed_url_list:\n",
    "    parsed_url=urlparse(url)\n",
    "    current_tenant=parsed_url.netloc\n",
    "    current_path=parsed_url.path\n",
    "\n",
    "    # Make sure only avature URLs are accounted\n",
    "    if TARGET_DOMAIN not in current_tenant:\n",
    "        continue\n",
    "\n",
    "    # Handle redirects and trackers\n",
    "    if REDIRECT_TAG in current_path or TRACK_TAG in current_path:\n",
    "        continue\n",
    "\n",
    "    # Handle Paths\n",
    "    if current_path=='/':\n",
    "        base_path=''\n",
    "    else:\n",
    "        base_path=current_path.rstrip('/').split('/')[1] \n",
    "\n",
    "    if base_path:\n",
    "        tenants[current_tenant].add(base_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6daf6f",
   "metadata": {},
   "source": [
    "### Build the Tenant Registry CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "307fe60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify if any career pages related keywords are present in path\n",
    "def is_career_path(path):\n",
    "    if not path:\n",
    "        return False\n",
    "    return any(kw in path.lower() for kw in CAREER_KEYWORDS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "758b7066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect base attributes for each Tenant and store in CSV\n",
    "tenant_registry=[]\n",
    "for tenant,paths in tenants.items():\n",
    "    for path in paths:\n",
    "        current_data={\n",
    "            'tenant':tenant,\n",
    "            'base_url':f\"https://{tenant}\",\n",
    "            'career_path':f\"/{path}\" if path else '/',\n",
    "            'full_url':f\"https://{tenant}/{path}\",\n",
    "            'is_career_page':is_career_path(path)\n",
    "        }\n",
    "        tenant_registry.append(current_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "748c2ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tenants=pd.DataFrame(tenant_registry)\n",
    "df_tenants=df_tenants.sort_values(by=['tenant','is_career_page'],ascending=[True,False])\n",
    "df_tenants.to_csv(TARGET_REGISTRY_PATH,index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226779d2",
   "metadata": {},
   "source": [
    "### Base Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea5781ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "AVATURE TENANTS - BREAKDOWN\n",
      "============================================================\n",
      "\n",
      "Overall:\n",
      "Total rows: 2,398\n",
      "Unique tenants: 536\n",
      "\n",
      "Page Type Breakdown:\n",
      "Career pages: 707 (29.5%)\n",
      "Non-career pages: 1,691 (70.5%)\n",
      "Total: 2,398\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(TARGET_REGISTRY_PATH)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"AVATURE TENANTS - BREAKDOWN\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Overall counts\n",
    "total_rows = len(df)\n",
    "unique_tenants = df['tenant'].nunique()\n",
    "\n",
    "print(f\"\\nOverall:\")\n",
    "print(f\"Total rows: {total_rows:,}\")\n",
    "print(f\"Unique tenants: {unique_tenants:,}\")\n",
    "\n",
    "# Breakdown by page type\n",
    "career_pages = df['is_career_page'].sum()\n",
    "non_career_pages = len(df[~df['is_career_page']])\n",
    "\n",
    "print(f\"\\nPage Type Breakdown:\")\n",
    "print(f\"Career pages: {career_pages:,} ({career_pages/total_rows*100:.1f}%)\")\n",
    "print(f\"Non-career pages: {non_career_pages:,} ({non_career_pages/total_rows*100:.1f}%)\")\n",
    "print(f\"Total: {career_pages + non_career_pages:,}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1aa0c3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tenant_from_domain(domain):\n",
    "    \"\"\"Extract base tenant from any subdomain format\"\"\"\n",
    "    if not domain or TARGET_DOMAIN not in domain:\n",
    "        return None\n",
    "    \n",
    "    domain = domain.lower().strip()\n",
    "    \n",
    "    if domain.count('.') == 2:\n",
    "        match = re.match(r'^([a-z0-9-]+)\\.avature\\.net$', domain)\n",
    "        if match and len(match.group(1)) > 2:\n",
    "            return domain\n",
    "    elif domain.count('.') >= 3:\n",
    "        match = re.search(r'([a-z0-9-]+)\\.avature\\.net', domain)\n",
    "        if match and len(match.group(1)) > 2:\n",
    "            return f\"{match.group(1)}.avature.net\"\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50185fa9",
   "metadata": {},
   "source": [
    "### Additional step for Seed URL expansion: CT Disocvery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3db8c5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_tenants=set(df['tenant'].unique())\n",
    "expanded_tenant_registry=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1274621f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_with_ct(existing_tenants):\n",
    "    \"\"\"\n",
    "    Strategy 1: Enhanced Certificate Transparency parsing\n",
    "    \"\"\"\n",
    "    discovered = set()\n",
    "    try:\n",
    "        response = requests.get(\n",
    "            \"https://crt.sh/?q=%.avature.net&output=json\",\n",
    "            timeout=180,\n",
    "            headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            print(f\"  Certificate records: {len(data):,}\")\n",
    "            \n",
    "            for entry in data:\n",
    "                name_value = entry.get('name_value', '')\n",
    "                \n",
    "                for name in name_value.split('\\n'):\n",
    "                    name = name.strip().lower()\n",
    "                    \n",
    "                    if 'avature.net' in name and '*' not in name:\n",
    "                        tenant = extract_tenant_from_domain(name)\n",
    "                        if tenant and tenant not in existing_tenants:\n",
    "                            discovered.add(tenant)\n",
    "            \n",
    "            print(f\"New tenants found: {len(discovered)}\")\n",
    "        else:\n",
    "            print(f\"Error: HTTP {response.status_code}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"  Error: {e}\")\n",
    "    \n",
    "    return discovered\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "603792a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Certificate records: 164\n",
      "New tenants found: 28\n"
     ]
    }
   ],
   "source": [
    "ct_tenants= expand_with_ct(existing_tenants)\n",
    "existing_tenants.update(ct_tenants)\n",
    "\n",
    "for tenant in ct_tenants:\n",
    "    for path in ['careers', 'jobs', 'talent', 'recruiting', 'talentcommunity']:\n",
    "        expanded_tenant_registry.append({\n",
    "            'tenant': tenant,\n",
    "            'base_url': f\"https://{tenant}\",\n",
    "            'career_path': f\"/{path}\",\n",
    "            'full_url': f\"https://{tenant}/{path}\",\n",
    "            'is_career_page': True,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d50ff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_with_company_search(existing_tenants):\n",
    "    \"\"\"\n",
    "    Strategy : Test Fortune 1000 + Global 500 companies\n",
    "    Direct HTTP HEAD requests (faster than DNS)\n",
    "    \"\"\"\n",
    "    print(\"\\nFortune 1000 + Global 500 brute force...\")\n",
    "    \n",
    "    # Comprehensive list of major companies\n",
    "    major_companies = [\n",
    "        # Technology (100 companies)\n",
    "        'microsoft', 'apple', 'google', 'alphabet', 'amazon', 'meta', 'facebook',\n",
    "        'ibm', 'oracle', 'sap', 'salesforce', 'adobe', 'cisco', 'intel', 'amd',\n",
    "        'nvidia', 'qualcomm', 'broadcom', 'micron', 'texas-instruments', 'ti',\n",
    "        'dell', 'hp', 'hpe', 'vmware', 'redhat', 'servicenow', 'workday',\n",
    "        'splunk', 'palo-alto', 'fortinet', 'crowdstrike', 'okta', 'zoom',\n",
    "        'slack', 'atlassian', 'datadog', 'snowflake', 'mongodb', 'elastic',\n",
    "        \n",
    "        # Finance (150 companies)\n",
    "        'jpmorgan', 'jpmorganchase', 'jpm', 'chase', 'bankofamerica', 'bofa',\n",
    "        'wellsfargo', 'wf', 'citi', 'citigroup', 'citibank', 'goldmansachs', 'gs',\n",
    "        'morganstanley', 'ms', 'ubs', 'credit-suisse', 'cs', 'deutschebank', 'db',\n",
    "        'barclays', 'hsbc', 'bnpparibas', 'bnp', 'societe-generale', 'sg',\n",
    "        'blackrock', 'vanguard', 'fidelity', 'statestreet', 'invesco',\n",
    "        'franklin-templeton', 'troweprice', 'capital-group', 'jpmorgan-asset',\n",
    "        'amex', 'american-express', 'visa', 'mastercard', 'discover',\n",
    "        'charles-schwab', 'schwab', 'tdameritrade', 'etrade', 'robinhood',\n",
    "        'prudential', 'metlife', 'aig', 'travelers', 'allstate', 'progressive',\n",
    "        'nationwide', 'liberty-mutual', 'usaa', 'state-farm',\n",
    "        \n",
    "        # Consulting (50 companies)\n",
    "        'deloitte', 'deloitteus', 'deloitteuk', 'deloittebe', 'deloitteau',\n",
    "        'pwc', 'pwcus', 'pwcuk', 'kpmg', 'kpmgus', 'kpmguk', 'ey', 'eyus', 'eyuk',\n",
    "        'accenture', 'accentureus', 'mckinsey', 'bcg', 'bain', 'booz', 'boozallen',\n",
    "        'oliverwyman', 'atkearney', 'rolandberger', 'lbg', 'capgemini', 'cognizant',\n",
    "        'infosys', 'wipro', 'tcs', 'hcl', 'atos', 'dxc',\n",
    "        \n",
    "        # Pharma/Healthcare (100 companies)\n",
    "        'pfizer', 'jnj', 'johnson-johnson', 'merck', 'abbvie', 'novartis',\n",
    "        'roche', 'sanofi', 'gsk', 'glaxosmithkline', 'astrazeneca', 'bms',\n",
    "        'bristol-myers', 'bristol', 'lilly', 'eli-lilly', 'gilead', 'biogen',\n",
    "        'amgen', 'regeneron', 'vertex', 'moderna', 'biontech', 'illumina',\n",
    "        'unitedhealth', 'uhg', 'anthem', 'elevance', 'cigna', 'humana', 'centene',\n",
    "        'hca', 'tenet', 'universal-health', 'hcahealthcare', 'commonspirit',\n",
    "        'ascension', 'providence', 'mayo', 'cleveland', 'johnshopkins', 'kaiser',\n",
    "        \n",
    "        # Manufacturing/Industrial (80 companies)\n",
    "        'ge', 'generalelectric', 'honeywell', 'siemens', '3m', 'caterpillar',\n",
    "        'deere', 'boeing', 'lockheed', 'lockheedmartin', 'raytheon', 'rtx',\n",
    "        'northrop', 'northropgrumman', 'generaldynamics', 'gd', 'l3harris',\n",
    "        'emerson', 'rockwell', 'schneider', 'abb', 'eaton', 'parker',\n",
    "        'ford', 'gm', 'general-motors', 'stellantis', 'fca', 'toyota', 'honda',\n",
    "        'nissan', 'hyundai', 'kia', 'vw', 'volkswagen', 'bmw', 'mercedes',\n",
    "        'daimler', 'audi', 'porsche', 'tesla', 'rivian', 'lucid',\n",
    "        \n",
    "        # Energy (60 companies)\n",
    "        'exxon', 'exxonmobil', 'chevron', 'shell', 'bp', 'total', 'totalenergies',\n",
    "        'conocophillips', 'cop', 'valero', 'marathon', 'phillips66',\n",
    "        'halliburton', 'slb', 'schlumberger', 'baker-hughes', 'weatherford',\n",
    "        'duke-energy', 'southern-company', 'nextera', 'dominion', 'exelon',\n",
    "        \n",
    "        # Retail/Consumer (100 companies)\n",
    "        'walmart', 'target', 'costco', 'homedepot', 'lowes', 'kroger',\n",
    "        'albertsons', 'publix', 'wegmans', 'bestbuy', 'macys', 'nordstrom',\n",
    "        'gap', 'tjx', 'ross', 'burlington', 'kohls', 'nike', 'adidas',\n",
    "        'pg', 'proctergamble', 'unilever', 'nestle', 'cocacola', 'pepsico',\n",
    "        'kraft', 'mondelez', 'mars', 'general-mills', 'kellogg', 'campbells',\n",
    "        'mcdonalds', 'starbucks', 'yum', 'chipotle', 'dominos', 'subway',\n",
    "        \n",
    "        # Telecom/Media (50 companies)\n",
    "        'att', 'verizon', 'tmobile', 'sprint', 'comcast', 'charter', 'cox',\n",
    "        'vodafone', 'orange', 'telefonica', 'bt', 'disney', 'warnermedia',\n",
    "        'paramount', 'cbs', 'nbc', 'universal', 'sony', 'fox', 'netflix',\n",
    "        \n",
    "        # Other (50 companies)\n",
    "        'fedex', 'ups', 'dhl', 'maersk', 'marriott', 'hilton', 'hyatt',\n",
    "        'aon', 'marsh', 'willis', 'cbre', 'jll', 'cushman', 'colliers',\n",
    "        'leidos', 'saic', 'caci', 'aecom', 'jacobs', 'fluor', 'bechtel',\n",
    "    ]\n",
    "    \n",
    "    print(f\"  Testing {len(major_companies)} major companies...\")\n",
    "    \n",
    "    discovered_tenants = set()\n",
    "    \n",
    "    def test_tenant(company):\n",
    "        \"\"\"Test if a company tenant exists via HTTP HEAD\"\"\"\n",
    "        tenant = f\"{company}.avature.net\"\n",
    "        \n",
    "        if tenant in existing_tenants:\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            response = requests.head(\n",
    "                f\"https://{tenant}/careers\",\n",
    "                timeout=5,\n",
    "                allow_redirects=True,\n",
    "                headers={'User-Agent': 'Mozilla/5.0'}\n",
    "            )\n",
    "            \n",
    "            if response.status_code in [200, 301, 302, 403]:\n",
    "                return tenant\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    found_count = 0\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = {executor.submit(test_tenant, company): company for company in major_companies}\n",
    "        \n",
    "        for future in as_completed(futures):\n",
    "            result = future.result()\n",
    "            if result:\n",
    "                discovered_tenants.add(result)\n",
    "                found_count += 1\n",
    "                if found_count % 10 == 0:\n",
    "                    print(f\"    Found {found_count} live tenants...\")\n",
    "    \n",
    "    print(f\"\\n  Live tenants found: {len(discovered_tenants)}\")\n",
    "    \n",
    "    if len(discovered_tenants) > 0:\n",
    "        print(f\"\\n  Sample:\")\n",
    "        for tenant in sorted(discovered_tenants)[:30]:\n",
    "            print(f\"    {tenant}\")\n",
    "    \n",
    "    return discovered_tenants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3776573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fortune 1000 + Global 500 brute force...\n",
      "  Testing 313 major companies...\n",
      "\n",
      "  Live tenants found: 2\n",
      "\n",
      "  Sample:\n",
      "    boozallen.avature.net\n",
      "    schneider.avature.net\n"
     ]
    }
   ],
   "source": [
    "search_based_tenants= expand_with_company_search(existing_tenants)\n",
    "existing_tenants.update(search_based_tenants)\n",
    "\n",
    "# Add to registry\n",
    "for tenant in search_based_tenants:\n",
    "    for path in ['careers', 'jobs', 'talent', 'recruiting']:\n",
    "        expanded_tenant_registry.append({\n",
    "            'tenant': tenant,\n",
    "            'base_url': f\"https://{tenant}\",\n",
    "            'career_path': f\"/{path}\",\n",
    "            'full_url': f\"https://{tenant}/{path}\",\n",
    "            'is_career_page': True,\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "86d21dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tenants from original seed URLs: 536\n",
      "Unique tenants from expanded seed URLs: 30\n",
      "Final rows: 2546\n"
     ]
    }
   ],
   "source": [
    "# Load seed-based registry\n",
    "df_seeds = pd.read_csv(TARGET_REGISTRY_PATH)\n",
    "print(f\"Unique tenants from original seed URLs: {df_seeds['tenant'].nunique()}\")\n",
    "\n",
    "# Create expanded tenants DataFrame\n",
    "df_expanded = pd.DataFrame(expanded_tenant_registry)\n",
    "print(f\"Unique tenants from expanded seed URLs: {df_expanded['tenant'].nunique()}\")\n",
    "\n",
    "\n",
    "# Combine both datasets\n",
    "df_combined = pd.concat([df_seeds, df_expanded], ignore_index=True)\n",
    "\n",
    "# Remove exact duplicates (same tenant + path)\n",
    "df_combined = df_combined.drop_duplicates(\n",
    "    subset=['tenant', 'career_path'], \n",
    "    keep='first'  # Keep seed version for duplicates\n",
    ")\n",
    "# Sort by tenant and career page priority\n",
    "df_combined = df_combined.sort_values(\n",
    "    by=['tenant', 'is_career_page'], \n",
    "    ascending=[True, False]\n",
    ")\n",
    "\n",
    "# Save combined dataset\n",
    "df_combined.to_csv(TARGET_REGISTRY_PATH, index=False)\n",
    "print(f'Final rows: {len(df_combined)}')\n",
    "\n",
    "# Also save just CT discoveries for reference\n",
    "df_expanded.to_csv(EXPANDED_SEED_URLS, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
